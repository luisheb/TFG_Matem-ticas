\documentclass[a4paper,11pt,spanish, twoside, leqno]{tfg-uam}

\usepackage[utf8]{inputenc}
\usepackage{amsfonts, amssymb, amsmath, amsthm}
\usepackage{graphicx}
\usepackage{color}
\usepackage{xcolor}
\usepackage{tikz}
\usepackage{listofitems} % for \readlist to create arrays
\usepackage{hyperref}
\usepackage{algorithmic}
\usepackage{algorithm}
\usepackage{mdframed}
\usepackage{marginnote}
\usepackage[backend=bibtex, style=numeric]{biblatex} 
\addbibresource{references.bib} % Link to your .bib file


\mdfsetup{%
linecolor=white,
backgroundcolor=gray!10,
}
\tikzstyle{mynode}=[thick,draw=black,fill=blue!20,circle,minimum size=18]

\newtheorem{teor}{Teorema}[chapter]
\newtheorem{lema}[teor]{Lema}
\newtheorem*{teorsin}{Teorema}


\renewcommand*{\raggedrightmarginnote}{\raggedright}

\theoremstyle{definition}
\newtheorem{defin}[teor]{Definici\'on}
\newtheorem{exmp}[teor]{Ejemplo}

\title{Redes Neuronales: aproximación de EDPs}
\author{Luis Hebrero Garicano}
\tutor{Julia Novo}
\curso{2024-2025}




%%%%%METADATOS: rellenar la info solicitada entre llaves
\usepackage{hyperref}
\hypersetup{
	pdfinfo={
            Title={Redes Neuronales: aproximacion de EDPs}, %Titulo del trabajo; ejemplo: Matematicas y desarrollo
            Author={Luis Hebrero Garicano}, %Autor del trabajo; ejemplo: Juan Sanchez
            Director1={julia.novo}, %Tutor1: en formato nombre.apellido, tal como aparece en la primera parte, antes de la arroba,  de su direcci�n de correo electr�nico de la UAM; ejemplo: fernando.soria
            Director2={ }, %Tutor2: en formato nombre.apellido, tal como aparece en la primera parte, antes de la arroba,  de su direcci�n de correo electr�nico de la UAM
            Ndirectores={1}, %Numero total de directores: 1 � 2
            Tipo={TFG}, %no tocar
            Curso={2024-25}, %no tocar
            Palabrasclave={ },% Palabras clave del trabajo, separadas por comas y sin acentos ni espacios; ejemplo: morfismos, formas modulares, ecuaciones elipticas
				}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}



\begin{abstract}[spanish]
Las redes neuronales son un modelo matemático inspirado en el funcionamiento cerebral que, en esencia, se utiliza para encontrar funciones: funciones que clasifican datos, que predicen valores o incluso que anticipan la siguiente palabra en una frase. En este trabajo, se estudiará cómo se puede aplicar esta capacidad de aproximación de funciones para resolver ecuaciones en derivadas parciales. Exploraremos distintas estrategias para construir estas redes y analizaremos su aplicación en problemas concretos, centrándonos en las ventajas que aportan con respecto a los métodos numéricos tradicionales, así como en los casos en los que una aproximación mediante redes neuronales no resulta efectiva.
\end{abstract}
\begin{abstract}[english]
Neural networks are a mathematical model inspired by the brain's functioning, primarily used to find functions: functions that classify data, predict values, or even anticipate the next word in a sentence. This work will explore how this function approximation capability can be applied to solve partial differential equations. We will investigate different strategies for constructing these networks and analyze their application to specific problems, focusing on the advantages they offer over traditional numerical methods, as well as the cases where a neural network-based approach proves ineffective.
\end{abstract}
\mainmatter


\chapter{Introducción y preliminares}\label{chap1}
\setcounter{page}{1}
Para poder entender las aproximaciones a las EDPs mediante redes neuronales, es necesario tener un conocimiento previo de las redes neuronales y de las ecuaciones en derivadas parciales. En este capítulo, se introducirán los conceptos básicos de ambos temas, así como las herramientas matemáticas necesarias para comprender el resto del trabajo.

\section{Introducción a las redes neuronales}\label{sec:RedesNeuronales}
Una red neuronal, de forma abstracta, es simplemente una función que toma una entrada y produce una salida. Es decir, una red neuronal, es una función $F$ que toma un vector de entrada $x$ y produce un vector de salida $y$, siendo $F: \mathbb{R}^n \rightarrow \mathbb{R}^m$. La red neuronal se compone de una serie de capas, cada una de las cuales está formada por un conjunto de neuronas. Cada neurona de una capa recibe una serie de entradas, las procesa y produce una salida. La salida de cada neurona se calcula mediante una función de activación, que puede ser de distintos tipos, como la función sigmoide, la función tangente hiperbólica o la función ReLU. Para entender este concepto nos vamos a centrar en el caso concreto de la red neuronal de la Figura \ref{fig:RedNeuronal}.


\begin{figure}[!ht]
    \centering
    \begin{tikzpicture}[x=2.2cm,y=1.4cm]
        \readlist\Nnod{2,2,3,3} % number of nodes per layer
        \readlist\colors{mylightred, mylightblue, mylightblue, mylightgreen} % color of each layer
        % \Nnodlen = length of \Nnod (i.e. total number of layers)
        % \Nnod[1] = element (number of nodes) at index 1
        \foreachitem \N \in \Nnod{ % loop over layers
          % \N     = current element in this iteration (i.e. number of nodes for this layer)
          % \Ncnt  = index of current layer in this iteration
          \foreach \i [evaluate={\x=\Ncnt; \y=\N/2-\i+0.5; \prev=int(\Ncnt-1);}] in {1,...,\N}{ % loop over nodes
            \node[mynode] (N\Ncnt-\i) at (\x,\y) {};
            \ifnum\Ncnt>1 % connect to previous layer
              \foreach \j in {1,...,\Nnod[\prev]}{ % loop over nodes in previous layer
                \draw[thick] (N\prev-\j) -- (N\Ncnt-\i); % connect arrows directly
              }
            \fi % else: nothing to connect first layer
          }
        }
    \end{tikzpicture}
    \caption{Esquema de una red neuronal con 4 capas.}
    \label{fig:RedNeuronal}
\end{figure}

Como se ve en la Figura \ref{fig:RedNeuronal}, la entrada en nuestra función está representada por los dos círculos de la izquierda, que representan los valores de entrada $x_1$ y $x_2$, siendo así la entrada $x\in\mathbb{R}^2$. Estos valores se multiplican por unos pesos ($W^{[2]}$)y se suman a un sesgo $b$. La salida de esta neurona se calcula mediante una función de activación. Así, los valores que ``llegan'' a la segunda capa de nuestra red neuronal serán de la forma
\begin{equation*}
    \sigma(W^{[2]}x+b^{[2]})\in\mathbb{R}^2,
\end{equation*}

Siendo $W^{[2]}\in\mathbb{R}^{2\times2}$ y el vector $b^{[2]}\in\mathbb{R}^2$. A partir de aquí, se repite el proceso para cada capa de la red neuronal, hasta llegar a la capa de salida, que nos dará el valor de salida de nuestra red neuronal. De forma visual, se pueden interpretar las flechas de la Figura \ref{fig:RedNeuronal} como los pesos por los que se va multiplicando.

En la tercera capa de la red neuronal, vemos que los valores que llegan de la capa 2, estos $\sigma(W^{[2]}x+b^{[2]})$, pertenecen a $\mathbb{R}^2$. De este modo, como tenemos 3 neuronas en la tercera capa, para obtener un valor perteneciente a $\mathbb{R}^3$, necesitamos una matriz $W^{[3]}\in\mathbb{R}^{3\times2}$ y un vector $b^{[3]}\in\mathbb{R}^3$. Así, el valor de nuestra red neuronal en la tercera capa será
\begin{equation*}
    \sigma(W^{[3]}\sigma(W^{[2]}x+b^{[2]})+b^{[3]})\in\mathbb{R}^3.
\end{equation*}

Finalmente, la capa de salida recibirá de la tercera capa un vector perteneciente a $\mathbb{R}^3$, por lo que necesitaremos una matriz $W^{[4]}\in\mathbb{R}^{3\times3}$ y un vector $b^{[4]}\in\mathbb{R}^3$. Así, el valor de salida de nuestra red neuronal, esa $F$ de la que habíamos hablado al principio, será
\begin{equation}
    F(x)=\sigma(W^{[4]}\sigma(W^{[3]}\sigma(W^{[2]}x+b^{[2]})+b^{[3]})+b^{[4]})\in\mathbb{R}^3.
\end{equation}\label{eq:RedNeuronal}

En general, una red neuronal se puede representar como una composición de funciones, donde cada función es una capa de la red neuronal. 

Nuestra intención con este tipo de funciones es ir variando los valores de las matrices $W$, también conocidos como pesos, y los vectores $b$ también conocidos como sesgos, para que la salida de nuestra red neuronal se acerque lo máximo posible a la salida deseada. 

Para entender esto, vamos a utilizar la red neuronal de la Figura \ref{fig:RedNeuronal} para resolver un problema concreto muy sencillo de clasificación. Supongamos que tenemos una serie de puntos en el plano, de tres tipos distintos, como los de la Figura \ref{fig:Clasificacion}, y queremos clasificarlos en tres grupos, los puntos de tipo azul, rojo y amarillo.


\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.5\textwidth]{Figuras/pic_xy.png}
    \caption{Puntos en el plano que marcan las dos categorías}
    \label{fig:Clasificacion}
\end{figure}

De este modo, nuestra red neuronal recibirá como entrada un punto del plano, y nos dirá a qué categoría pertenece, devolviendo $(1,0,0)^T$ si es de la categoría azul, $(0,1,0)^T$ si es de la categoría roja y $(0,0,1)^T$ si es de la categoría amarilla.

Lo siguiente que queremos hacer será entrenar la red neuronal, es decir, ajustar los pesos y sesgos de la red neuronal para que la salida se acerque lo máximo posible a la salida deseada. Es decir, que cuando se introduzca un punto de un tipo concreto, la salida lo asigne a la categoría adecuada. 

Designamos a $y(x)$ como la salida deseada de nuestra red neuronal, y a $F(x)$ como la salida real. Así, el error vendrá dado en función de los pesos y sesgos de la siguiente forma
\begin{equation*}
    E(W^{[2]},W^{[3]},W^{[4]},b^{[2]},b^{[3]},b^{[4]})=\frac{1}{2}\sum_{x\in X}\|y(x)-F(x)\|^2,
\end{equation*}
donde $X$ es el conjunto de puntos que tenemos para entrenar la red neuronal, en nuestro caso, serán 15. Esta función es conocida como función de coste.

Así, lo que queremos hacer es minimizar esta función, es decir, encontrar los pesos que minimicen la función $E$. Para ello, se utilizan algoritmos de optimización, como el descenso del gradiente. Este proceso es conocido como el entrenamiento de la red neuronal. Si se logra con éxito, la red neuronal será capaz de clasificar correctamente los puntos en el plano. En este caso concreto, al entrenar la red neuronal, se obtiene la clasificación de la Figura \ref{fig:ClasificacionFinal}, en la que simplemente hemos aplicado nuestra función para cada punto del plano y lo hemos sombreado de acuerdo a la clasificación que se le ha dado.

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.5\textwidth]{Figuras/classifier_back.png}
    \caption{Puntos en el plano que marcan las dos categorías}
    \label{fig:ClasificacionFinal}
\end{figure}

Más adelante entenderemos con más detalle como es este proceso de entrenamiento.

\subsection{Comentarios sobre la función sigmoide}
Como hemos visto con el ejemplo anterior, las redes neuronales se pueden utilizar para generar funciones. A su vez, estas funciones se utilizan para resolver problemas de forma aproximada. En el ejemplo de la Figura \ref{fig:RedNeuronal}, la función red neuronal clasifica cualquier parte del plano en una de las tres categorías sombreadas a partir del entrenamiento. Dicho entrenamiento fija los valores de los pesos y sesgos, y por tanto define la función red neuronal (en el ejemplo define la función \eqref{eq:RedNeuronal}).

Como las redes neuronales se utilizan para aproximar problemas de tipos muy distintos, una de las características deseables es que sean  capaces de aproximar el conjunto de funciones "mayor posible".

Para poder lograr este objetivo, se necesitan las funciones de activación. Como ejercicio, supongamos que en nuestra ecuación \eqref{eq:RedNeuronal} en lugar de utilizar la función sigmoide, no utilizamos ninguna función de activación, es decir, que nuestra red neuronal es simplemente una composición de funciones lineales. En este caso, nuestra red tendría la siguiente forma

\begin{equation*}
    F(x)=W^{[4]}(W^{[3]}(W^{[2]}x+b^{[2]})+b^{[3]})+b^{[4]}\in\mathbb{R}^3.
\end{equation*}

Claramente, una función lineal definida de forma global puede estar muy lejos de aproximar bien funciones generales. De este modo, parece por tanto razonables utilizar funciones de activación no lineales. La función sigmoide es una de las más utilizadas, pero existen otras como la función tangente hiperbólica o la función ReLU. En este trabajo, nos centraremos en la función sigmoide, que se define como
\begin{equation*}
    \sigma(x)=\frac{1}{1+e^{-x}}.
\end{equation*}

Esta función tiene la ventaja de que su derivada es fácil de calcular, y es precisamente esta derivada la que se utiliza en el algoritmo de entrenamiento de la red neuronal.

Un resultado relevante para justificar el uso de funciones de activación no lineales es el siguiente es el propuesto por Pinkus \cite[Theorem 3.1]{pinkus1999approximation}. Este resultado es para redes neuronales de una sola capa.

\begin{teor}[Pinkus]
    Sea $\sigma\in C(\mathbb{R})$ y sea conjunto $\mathcal{M}(\sigma) = \text{span}\{\sigma(w\cdot x + b): b \in \mathbb{R}, w \in \mathbb{R}^n\}$, se cumple que
    
    Para cualquier $f \in C(\mathbb{R}^n)$, cualquier conjunto compacto $K\in \mathbb{R}^n$ y cualquier $\epsilon > 0$, existe una función $g\in \mathcal{M}(\sigma)$ tal que $\max_{x\in K}|f(x)-g(x)|<\epsilon$. Si y solo si $\sigma$ no es una función polinómica.
\end{teor}
De forma más intuitiva, cualquier función $f \in C(\mathbb{R}^n)$, se puede aproximar tan bien como se quiera con una red neuronal de una sola capa si y solo si la función de activación no es polinómica.

Este resultado nos aporta una intuición de por qué las funciones de activación no lineales son necesarias para aproximar funciones de forma general pues, de no ser funciones no lineales, habría muchas funciones que no podríamos aproximar. 

\section{Conceptos preliminares sobre las ecuaciones en derivadas parciales}

En este trabajo nos vamos a centrar en las ecuaciones en derivadas parciales elípticas, definidas con la siguiente forma general.

\begin{mdframed}
\begin{defin}\label{def:EDP_eliptica}
    Dado un conjunto $\Omega$, acotado y abierto en $\mathbb{R}^n$, decimos que una ecuación en derivadas parciales es elíptica si es de la siguiente forma:
    \begin{equation}\label{eq:EDP_eliptica}
        -\sum_{i,j=1}^{n} \frac{\partial}{\partial x_j}\left( a_{ij}(x)\frac{\partial u}{\partial x_i}\right) + \sum_{i=1}^{n} b_i(x)\frac{\partial u}{\partial x_i} + c(x)u = f(x), \qquad x\in\Omega.
    \end{equation}
    Donde los coeficientes $a_{ij}(x)$, $b_i(x)$, $c(x)$ y $f$ son funciones que satisfacen las siguientes condiciones
\begin{align}
    a_{ij} \in C^1(\overline{\Omega}),& \qquad i,j = 1, \dots ,n \label{eq:condiciones_EDP_eliptica_a} \\
    b_i, c \in C(\overline{\Omega}),& \qquad i = 1, \dots ,n \\
    c \in C(\overline{\Omega}),& \\
    f\in C(\overline{\Omega})&\label{eq:condiciones_EDP_eliptica_f}
\end{align}
Además, se cumples las condiciones de elipticidad uniforme, es decir
\begin{equation}
    \sum_{i,j=1}^n a_{ij}(x) \xi_i \xi_j \geq c_0 \sum_{i=1}^n \xi_i^2, \quad \forall \xi = (\xi_1, \ldots, \xi_n) \in \mathbb{R}^n, \quad x \in \overline{\Omega};
\end{equation}
\end{defin}
\end{mdframed}

Concretamente, a lo largo del trabajo, nos centraremos en problemas de condición de frontera de Dirichlet, es decir, problemas en los que se cumple que
\begin{equation}
    u(x) = c, \qquad \forall x\in\partial\Omega.
\end{equation}

En la formulación que hemos dado de las ecuaciones en derivadas parciales elípticas, nos estábamos refiriendo a su formulación en forma fuerte. No obstante, en muchos casos, no es posible encontrar una solución en forma fuerte, es decir, una función que cumpla la ecuación en todo el dominio y que además cumpla las condiciones de frontera. En estos casos, se recurre a la  formulación débil de la ecuación, que permite encontrar una solución en un espacio de funciones más amplio. Este espacio de funciones es el espacio de Hilbert Sobolev. Para poder definirlo, primero veremos el espacio de Sobolev $H^1(\Omega)$.

\begin{mdframed}
\begin{defin}
    Seam $\Omega$ un conjunto abierto de $\mathbb{R}^n$. Definimos el espacio de Sobolev $H^1(\Omega)$ como el conjunto de funciones en el siguiente conjunto
    \begin{equation}
        H^1(\Omega)=\{u\in L^2(\Omega): \frac{\partial u}{\partial x_i}\in L^2(\Omega), \, i=1,\dots,n\}.
    \end{equation}
    En este espacio, se define la norma de funciones de con la siguiente ecuación
    \begin{equation}
        \|u\|_{H^1(\Omega)}=\left(\|u\|^2_{L^2(\Omega)} + \sum_{i=1}^{n}\left\|\frac{\partial u}{\partial x_i}\right\|^2_{L^2(\Omega)}\right)^{1/2}.
    \end{equation}
\end{defin}
\end{mdframed}
    
Así, el espacio $H_0^1(\Omega)$ es el cierre de las funciones de $C_0^\infty(\Omega)$ en la norma de $H^1(\Omega)$. Es decir, $H_0^1(\Omega)$ es el conjunto de funciones $u\in H^1(\Omega)$ que se obtienen como límite en $H^1(\Omega)$ de una serie de funciones $\{u_m\}_{m=1}^\infty$ todas ellas en $C_0^\infty(\Omega)$. Así, si $\partial\Omega$ es suficientemente regular, $H_0^1(\Omega)$ es el siguiente conjunto.
    
\begin{equation}
    H_0^1(\Omega)=\{u\in H^1(\Omega): u=0 \text{ en } \partial\Omega\}.
\end{equation}

Con esto, podemos definir la solución débil de una ecuación en derivadas parciales elíptica de la siguiente forma.
\begin{mdframed}
\begin{defin}\label{def:SolucionDebil}
    Dadas las funciones $a_{ij} \in L^\infty(\Omega), \, i,j = 1,\dots, n, \, b_i \in L^\infty(\Omega), i= 1, \dots, n, \, c\in L^\infty(\Omega)$, y la función $f\in L^2(\Omega)$. Decimos que la función $u\in H^1_0(\Omega)$ es una solución débil de la ecuación \eqref{eq:EDP_eliptica} si se cumples que, 
    \begin{equation}\label{eq:SolucionDebil}
        \begin{split}
            \sum_{i,j=1}^{n} \int_\Omega a_{ij}(x) \frac{\partial u}{\partial x_i} \frac{\partial \varphi}{\partial x_j}\,dx + \sum_{i=1}^{n} \int_\Omega b_i(x)\frac{\partial u}{\partial x_i} \varphi \,dx  \\+ \int_\Omega c(x)u \varphi \,dx = \int_\Omega f(x)\varphi(x) dx, \qquad \forall \varphi \in H^1_0(\Omega).
        \end{split}
    \end{equation}
\end{defin}
\end{mdframed}

Para simplificar esta engorrosa notación, nos interesa definir la siguiente forma bilineal y lineal. 
\begin{equation}
    a(u,\varphi) = \sum_{i,j=1}^{n} \int_\Omega a_{ij}(x) \frac{\partial u}{\partial x_i} \frac{\partial \varphi}{\partial x_j}\,dx + \sum_{i=1}^{n} \int_\Omega b_i(x)\frac{\partial u}{\partial x_i} \varphi \,dx  + \int_\Omega c(x)u \varphi \,dx,
\end{equation}
y,
\begin{equation}
    l(\varphi) = \int_\Omega f(x)\varphi(x) dx.
\end{equation}

De este modo, nuestro problema elíptico en forma debil se puede expresar de la siguiente forma.

\begin{equation}
    a(u,\varphi) = l(\varphi) \quad \forall \varphi\in H^1_0(\Omega).
\end{equation}
%Introducir la idea y usar el ejemplo del apartado anterior par ademostrar que no todas las ecuciones en forma fuerte tienen solución



%quiza tenga sentido hablar de que ni siquiera en forma debil se puede encontrar la solución, y que por eso se recurre a métodos alternativos (metodos numéricos)

%también puede tener sentido hablar de las ecuaciones en las que la solucion es el mínimo de una funcion, y que por eso se puede resolver con redes neuronales

\section{Métodos numéricos tradicionales: el método de los elementos finitos}
% hablar de como funciona en detalle, 

El método de los elementos finitos (MEF) es una técnica numérica para resolver ecuaciones en derivadas parciales. Este método es ampliamente utilizado en ingeniería y ciencias aplicadas porque permite aproximar soluciones en dominios complejos.

Para un problema elíptico con condiciones de frontera, se parte de una ecuación en su formulación débil. Como hemos visto en el apartado anterior, este problema se puede formular de forma muy simplificada como:
\begin{equation*}
    a(u,\varphi) = l(\varphi) \quad \forall \varphi\in V,
\end{equation*}
Donde $V$ es el espacio de funciones en el que están nuestras soluciones. En el caso del problema con condiciones homogéneas, este espacio será $V = H_0^1(\Omega)$.

Lo siguiente que se hace es dividir el dominio $\Omega$ en un conjunto de subdominios más pequeños, llamados elementos finitos. Por ejemplo, si estamos trabajando con un problema de una dimensión, con $\Omega =(0,1)$, dividimos $\overline{\Omega} = [0,1]$ en $N$ subintervalos $[x_i,x_{i+1}], \, i = 1, \dots, N-1$, como se hace en la Figura \ref{fig:DivisionOmega}.

\begin{figure}
    \centering
    \label{fig:DivisionOmega}
    \begin{tikzpicture}
        \draw[thick] (0,0) -- (12,0); % Adjusted length of the line
        \foreach \x in {0,2,4,6,8,10,12} % Adjusted positions of the ticks
        \draw (\x cm,3pt) -- (\x cm,-3pt);
        \draw (0,0) node[below=3pt] {$x_0 = 0$};
        \draw (2,0) node[below=3pt] {$x_1$};
        \draw (4,0) node[below=3pt] {$x_2$};
        \draw (6,0) node[below=3pt] {$x_3$};
        \draw (8,0) node[below=3pt] {$\dots$};
        \draw (10,0) node[below=3pt] {$x_{N-2}$};
        \draw (12,0) node[below=3pt] {$x_{N-1}=1$};
    \end{tikzpicture}
    \caption{División de $\Omega = (0,1)$ en $N$ elementos finitos}
\end{figure}

A esta subdivision, se le asocia una base de polinomios a trozos. Así, se reemplaza el subespacio de funciones que habíamos llamado $V$ por un subespacio de dimensión finita $V_h$ formado por polinomios a trozos  de grado fijo. Siguiendo nuestro ejemplo de antes, la base de polinomios que vamos a utilizar será la de los polinomios como los vistos en la Figura \ref{fig:BasePolinomios}. Definidos de la siguiente forma.
\begin{equation*}
    \phi_i(x) = \begin{cases}
        \frac{x-x_{i-1}}{x_i-x_{i-1}}, & \text{si } x\in[x_{i-1},x_i],\\
        \frac{x_{i+1}-x}{x_{i+1}-x_i}, & \text{si } x\in[x_i,x_{i+1}],\\
        0, & \text{en otro caso}.
    \end{cases} 
\end{equation*}

Así, en este ejemplo, nuestro espacio de funciones será $V_h = \text{span}\{\phi_1,\dots,\phi_N\}$, donde $N$ es el número de elementos finitos en los que hemos dividido el dominio. De este modo, al buscar soluciones en este nuevo espacio de funciones, nuestra ecuación diferencial elíptica se convertiría en encontrar los $u_h\in V_h$ tal que

\begin{figure}
    \centering
    \label{fig:BasePolinomios}
    \begin{tikzpicture}[scale=0.5]
        \draw[thick] (0,0) -- (12,0); % Adjusted length of the line
        \draw (6 cm,100pt) -- (6 cm,-5pt);
        \draw (1 cm,5pt) -- (1 cm,-5pt);
        \draw (11 cm,5pt) -- (11 cm,-5pt);
        \draw[thick] (1,0) -- (6,100pt) -- (11,0);
        \draw (1,0) node[below=3pt] {$x_{i-1}$};
        \draw (6,0) node[below=3pt] {$x_i$};
        \draw (11,0) node[below=3pt] {$x_{i+1}$};
    \end{tikzpicture}
    \caption{Polinomio $\phi_i$}
\end{figure}

\begin{equation*}
    a(u_h,v_h) = l(v_h) \quad \forall v_h\in V_h,
\end{equation*}


De forma intuitiva, lo que se hace es que en vez de buscar una solución en un espacio de funciones infinito, como es $V$, se busca una solución en un espacio de funciones finito, como es $V_h$. Para poder hacer eso, que nos simplifica mucho el problema, lo que hemos hecho es que nuestro dominio, lo hemos dividido en subdominios más pequeños a partir de los cuales hemos construido nuestro nuevo espacio de funciones. 

Al hacer esto, ahora, encontrar una solución se convierte en encontrar los coeficientes en la base de polinomios a trozos, es decir, los $U_i$ en la siguiente ecuación
\begin{equation}
    u_h = \sum_{i=1}^{N} U_i\phi_i.
\end{equation}
Es decir, resolver la ecuación diferencial se convierte en encontrar $U=(U_1,\dots, U_N) \in \mathbb{R}^N$ que cumplen:
\begin{equation}
    \sum_{i=1}^{N} a\left( \phi_i,\phi_j\right)U_i = l(\phi_j) \quad \forall j = 1,\dots,N.
\end{equation}

Esto se traduce en un sistema lineal de la forma $AU = b$, donde $A$ es la matriz de rigidez (con entradas $A_{ij}=a\left( \phi_i,\phi_j\right)$), y $b$ es el vector de términos fuente (con entradas $b_j = l(\phi_j)$). A este nuevo sistema lineal se le pueden aplicar métodos numéricos tradicionales para resolverlo, como la factorización LU, encontrando así los coeficientes $U$ que nos dan $u_h$, la aproximación de $u$.
\begin{mdframed}
\begin{exmp}
    Veamos ahora un ejemplo concreto de la aplicación del FEM a través de la ecuación de Poisson. El objetivo es encontrar un campo escalar $ u $ sobre un dominio $\Omega \subset \mathbb{R}^n$ que satisfaga:
    \begin{equation}
    \begin{aligned}
    - \nabla^2 u &= f \quad \text{en} \ \Omega, \\
    u &= 0 \quad \text{en} \ \Gamma_D, \\
    \nabla u \cdot n &= g \quad \text{en} \ \Gamma_N,
    \end{aligned}
    \end{equation}
    donde $ f $ es un término fuente, $ g $ es un flujo en la frontera, $ n $ es el vector normal unitario, $\Gamma_D$ y $\Gamma_N$ son partes de la frontera donde se aplican las condiciones de contorno de Dirichlet y Neumann, respectivamente.

    El método de elementos finitos (FEM) aproxima $ u $ transformando el problema en su forma debil y resolviéndolo en un espacio de funciones de dimensión finita. La forma fuerte del problema se convierte en:
    \begin{equation}
    a(u, v) = l(v) \quad \forall \ v \in V,
    \end{equation}
    donde:
    \begin{itemize}
        \item $ a(u, v) = \int_{\Omega} \nabla u \cdot \nabla v \, \text{d}x $
        \item $ l(v) = \int_{\Omega} f v \, \text{d}x + \int_{\Gamma_N} g v \, \text{d}s $
    \end{itemize}

    Al discretizar el espacio $V$, el FEM transforma esta ecuación en un sistema de ecuaciones lineales que se puede resolver numéricamente. En este caso concreto usaremos un dominio rectangular $\Omega = [0,2] \times [0,1]$, en el que se imponen las siguientes condiciones:  
    \begin{itemize}
        \item Frontera de Dirichlet $\Gamma_D$ en los bordes verticales ($x=0$ y $x=2$) con $u=0$,  
        \item Frontera de Neumann $\Gamma_N$ en los bordes horizontales ($y=0$ y $y=1$) con flujo $g(x) = \sin(5x)$.
        \item Término fuente $f(x, y) = 10 \cdot\exp \left( - \frac{(x - 0.5)^2 + (y - 0.5)^2}{0.02} \right)$.  
    \end{itemize}

    Bajo estas condiciones, si usamos el paquete de python FEniCS, podemos resolver el problema obteniendo el siguiente resultado.
    \begin{figure}[H] 
        \centering
        \includegraphics[width=0.5\textwidth]{Figuras/poisson.png}
        \caption{Solución de la ecuación de Poisson}
        \label{fig:poisson}
    \end{figure}
     Se puede apreciar en la Figura \ref{fig:poisson} la malla de elementos finitos utilizada para la aproximación de la solución, siendo esta la que da lugar a la base de polinomios a trozos que hemos mencionado anteriormente. 
\end{exmp}
\end{mdframed}

\section{El problema elíptico autoadjunto}

Vamos a considerar ahora un caso particular que es el llamado problema elíptico autoadjunto, el cual permite caracterizar las soluciones de las EDP elípticas como el mínimo de un funcional. Esto conecta de manera lógica con el enfoque de redes neuronales para aproximar soluciones, donde la función de coste de la red neuronal se puede definir como esta función. Al minimizarla, se obtiene una solución aproximada del problema original. No obstante, esto lo veremos más adelante en detalle. De momento, se define el problema elíptico autoadjunto de la siguiente forma.

\begin{mdframed}
\begin{defin}
    Dado un conjunto $\Omega$, acotado y abierto en $\mathbb{R}^n$, decimos que una ecuación en derivadas parciales es elíptica autoadjunta si es elíptica, es decir, se cumplen las condiciones de la Definición \eqref{def:EDP_eliptica}, y además se cumplen las siguientes condiciones de simetría en los coeficientes.
    \begin{equation}\label{eq:simetria_a}
        \begin{split}
            a_{ij} = a_{ji},\qquad &i,j = 1,\dots,n,\\
            b_i = 0, \qquad &i = 1,\dots,n,
        \end{split}
    \end{equation}
\end{defin}
\end{mdframed}
Bajo estas condiciones, nuestro problema se puede formular de la siguiente forma.
\begin{equation}
    \begin{cases}
        -\sum_{i,j=1}^{n} \frac{\partial}{\partial x_j}\left( a_{ij}(x)\frac{\partial u}{\partial x_i}\right) + c(x)u = f(x), & x\in\Omega,\\
        u(x) = 0, & x\in\partial\Omega.
    \end{cases}
\end{equation}

En un problema autoadjunto se pueden caracterizar las soluciones débiles como el mínimo de un funcional. Esto es así por el siguiente resultado.
\begin{lema} \label{lema:MinimoFuncion}
    Las siguientes afirmaciones son equivalentes:
    \begin{enumerate}
        \item Encontrar $u\in H_0^1(\Omega)$ tal que $a(u,\varphi) = l(\varphi) \quad \forall \varphi\in H_0^1(\Omega)$
        \item Encontrar $u\in H_0^1(\Omega)$ tal que $J(u) \leq J(\varphi) \quad \forall\varphi\in H_0^1(\Omega)$, siendo $J(u)$ la siguiente función
        \begin{equation*}
            J(u) = \frac{1}{2}a(u,u) - l(u), \quad u\in H_0^1(\Omega)
        \end{equation*}
    \end{enumerate}
\end{lema}

\chapter{Aproximación de EDPs mediante redes neuronales}\label{chap2}

\section{PINN: Physics-Informed Neural Networks}
\subsection{Introducción}
Las PINN, o Physics-Informed Neural Networks, son una técnica que combina la resolución de ecuaciones en derivadas parciales con redes neuronales. La idea es que, en vez de resolver la ecuación diferencial directamente o con métodos numéricos tradicionales, se entrena una red neuronal para que aproxime la solución de la ecuación. 

Como habíamos comentado en la Sección \ref{sec:RedesNeuronales}, las redes neuronales son capaces de aproximar cualquier función, por lo que, en teoría, pueden aproximar cualquier solución de una ecuación diferencial. De este modo, las PINN van a aprovechar esto, definiendo la aproximación de nuestra solución $\hat{u}$, como la salida de nuestra función red neuronal $u(x,t;\mathbf{\theta})$. Así, la función en la Figura \ref{fig:PIN} sería la aproximación de la solución de la ecuación diferencial.
\begin{figure}[htbp]
    \centering
    \label{fig:PIN}
    \includegraphics[scale=0.7]{Figuras/neural_network_improved.pdf}
    \caption{Esquema de una PINN}
\end{figure}

\subsection{Formulación de las PINN}
Consideramos una EDP parametrizada por $\lambda$, definida en función $u(\mathbf{x})$ con $\mathbf{x} = (x_1, \ldots, x_d)$, en un dominio $\Omega \subset \mathbb{R}^d$:
\marginnote{Creo que habría \\que ser más \\coherente\\ con la notación introducida.\\ Lo dejo así\\por coherencia\\con el paper\\igual habría que\\cambiarlo}
\begin{equation} 
    f\left(\mathbf{x}; \frac{\partial u}{\partial x_1}, \ldots, \frac{\partial u}{\partial x_d}, \frac{\partial^2 u}{\partial x_1^2}, \ldots, \frac{\partial^2 u}{\partial x_1 \partial x_d}, \ldots; \lambda\right) = 0, \quad \mathbf{x} \in \Omega,
\end{equation}
Con condición de frontera $u(\mathbf{x}) = g(\mathbf{x})$ en $\partial \Omega$. Para poder construir y ajustar los pesos de la red neuronal es esencial tener una función de coste, es decir, una función que nos diga como de buena es nuestra aproximación. En el caso de las PINN, la función de coste se define como la suma de dos términos ajustados por unos pesos. El primero de ellos, se encarga de verificar la ecuación diferencial, es decir, que la función red neuronal aproxima la ecuación diferencial en todo el dominio. El segundo término, se encarga de verificar las condiciones de frontera e iniciales.
\begin{equation}
    \mathcal{L}(\boldsymbol{\theta}; \mathcal{T}) = w_f \mathcal{L}_f(\boldsymbol{\theta}; \mathcal{T}_f) + w_b \mathcal{L}_b(\boldsymbol{\theta}; \mathcal{T}_b),
\end{equation}
donde $w_f$ y $w_b$ son pesos que se ajustan para dar más importancia a un término u otro y
\begin{align}
    \mathcal{L}_f(\boldsymbol{\theta}; \mathcal{T}_f) &= \frac{1}{|\mathcal{T}_f|} \sum_{\mathbf{x} \in \mathcal{T}_f} \left\| f\left( \mathbf{x}; \frac{\partial \hat{u}}{\partial x_1}, \ldots, \frac{\partial \hat{u}}{\partial x_d}, \frac{\partial^2 \hat{u}}{\partial x_1^2}, \ldots, \frac{\partial^2 \hat{u}}{\partial x_1 \partial x_d}, \ldots; \lambda \right) \right\|_2^2, \\
    \mathcal{L}_b(\boldsymbol{\theta}; \mathcal{T}_b) &= \frac{1}{|\mathcal{T}_b|} \sum_{\mathbf{x} \in \mathcal{T}_b} \left\| B(\hat{u}, \mathbf{x}) \right\|_2^2,
\end{align}

En estas ecuaciones, $\mathcal{T}_f$ y $\mathcal{T}_b$ son conjuntos de puntos en los que se evaluarán las funciones de coste, siendo $\mathcal{T}= \mathcal{T}_f\cup\mathcal{T}_b$, conocidos como puntos de colocación o ``collocation points''. En el caso de $\mathcal{L}_f$, se evaluará en puntos del dominio pues $\mathcal{T}_f\subset\Omega$, mientras que en $\mathcal{L}_b$ se evaluará en puntos de la frontera, pues $\mathcal{T}_f\subset\partial\Omega$. Obviamente, estos conjuntos son necesarios pues a nivel computacional es imposible calcular derivadas e integrales en un espacio continuo. Existe mucha literatura sobre como tomar estos puntos pues, al igual que en FEM la malla impacta el resultado, en las PINN, el conjunto $\mathcal{T}$ determina como de bien nuestra red neuronal se ajusta a la solución \cite{münzer2022curriculumtrainingbasedstrategydistributingcollocation}\cite{aikawa2024improving}\cite{matsubara2023goodlatticetrainingphysicsinformed}\cite{subramanian2022adaptiveselfsupervisionalgorithmsphysicsinformed}\cite{hou2023enhancing}.  

Dada la función de coste definida y la distribución de los puntos de colocación, el entrenamiento de la red neuronal se reduce a resolver un problema de optimización: encontrar los parámetros $\theta$ que minimizan la función de coste $\mathcal{L}(\boldsymbol{\theta}; \mathcal{T})$. Para ello, es habitual emplear métodos de optimización basados en gradientes, como Adam o L-BFGS. Estos permiten ajustar iterativamente los parámetros de la red para aproximar la solución $\hat{u}$ a la ecuación en derivadas parciales y a las condiciones asociadas (iniciales y de contorno).

Una ventaja fundamental del uso de redes neuronales en este contexto es la diferenciación automática, una técnica numérica muy potente que facilita la obtención de las derivadas de $\hat{u}$ con respecto a sus entradas de forma exacta y eficiente. Este mecanismo elimina la necesidad de derivaciones simbólicas o aproximaciones numéricas de las derivadas, lo que simplifica significativamente el cálculo de las derivadas necesarias para formular la función de coste, tanto a nivel del término de residuo interno de la EDP como en los términos asociados a las condiciones de frontera o iniciales.

A continuación, vamos a ver dos ejemplos para ver como se aplican las PINN a problemas concretos.

\begin{mdframed}
    \begin{exmp}
        
        Resolveremos una ecuación de calor:
        \begin{equation*}
        \frac{\partial u}{\partial t} = \alpha \frac{\partial^2 u}{\partial x^2}, \quad x \in [0, 1], \quad t \in [0, 1]
        \end{equation*}
        donde \(\alpha = 0.4\) es la constante de difusividad térmica. Con condiciones de frontera de Dirichlet:
        \begin{equation*}
        u(0, t) = u(1, t) = 0,
        \end{equation*}
        y condición inicial periódica (sinusoidal):
        \begin{equation*}
        u(x, 0) = \sin\left(\frac{n \pi x}{L}\right), \quad 0 < x < L, \quad n = 1, 2, \ldots
        \end{equation*}
        donde \(L = 1\) es la longitud de la barra y \(n = 1\) es la frecuencia de la condición inicial sinusoidal.
        Para este problema, sabemos que la solución exacta es:
        \begin{equation*}
        u(x, t) = e^{-\frac{n^2 \pi^2 \alpha t}{L^2}} \sin\left(\frac{n \pi x}{L}\right).
        \end{equation*}
        Que si la vemos de forma gráfica, obtenemos la Figura \ref{fig:calor_exacta}.
        \begin{figure}[H] 
            \centering
            \includegraphics[width=0.5\textwidth]{Figuras/calor_exacta.png}
            \caption{Solución de la ecuación de calor}
            \label{fig:calor_exacta}
        \end{figure}
        Si nos ayudamos de la librería DeepXDE, podemos programar la red neuronal y entrenarla para que aproxime la solución de la ecuación de calor. El resultado obtenido es el obtenido en la Figura \ref{fig:calor_estimacion}.
        \begin{figure}[H] 
            \centering
            \includegraphics[width=0.5\textwidth]{Figuras/calor_estimacion.png}
            \caption{Aproximación de la solución de la ecuación de calor}
            \label{fig:calor_estimacion}
        \end{figure}

    \end{exmp}
\end{mdframed}

No obstante, las PINN pueden presentar errores elevados incluso en sistemas físicos relativamente simples. El problema, según se diagnostica en \cite{krishnapriyan2021characterizingpossiblefailuremodes} radica en el uso de restricciones demasiado suaves en $\mathcal{L}$, lo cual provoca que la función de perdida sea difícil de optimizar. A continuación, vemos uno de los ejemplos que presentan en el paper en los que las PINN fallan.

\begin{mdframed}
    \begin{exmp}
        Consideremos la ecuación de Poisson en una dimensión, con condiciones de frontera de Dirichlet homogéneas. Es decir, queremos encontrar $u(x)$ tal que
        \begin{equation}
            \begin{cases}
                -\frac{d^2 u}{dx^2} = f(x), & x\in(0,1),\\
                u(0) = u(1) = 0.
            \end{cases}
        \end{equation}
        Para resolver este problema con una PINN, se puede definir la función de coste como
        \begin{equation}
            \mathcal{L}(\boldsymbol{\theta}; \mathcal{T}) = w_f \mathcal{L}_f(\boldsymbol{\theta}; \mathcal{T}_f) + w_b \mathcal{L}_b(\boldsymbol{\theta}; \mathcal{T}_b),
        \end{equation}
        donde
        \begin{align}
            \mathcal{L}_f(\boldsymbol{\theta}; \mathcal{T}_f) &= \frac{1}{|\mathcal{T}_f|} \sum_{x \in \mathcal{T}_f} \left\| -\frac{d^2 \hat{u}}{dx^2} - f(x) \right\|_2^2, \\
            \mathcal{L}_b(\boldsymbol{\theta}; \mathcal{T}_b) &= \frac{1}{|\mathcal{T}_b|} \sum_{x \in \mathcal{T}_b} \left\| \hat{u}(x) \right\|_2^2.
        \end{align}
        En este caso, $\mathcal{T}_f$ y $\mathcal{T}_b$ serán conjuntos de puntos en los que se evaluarán las funciones de coste, siendo $\mathcal{T}= \mathcal{T}_f\cup\mathcal{T}_b$. Para entrenar la red neuronal, se resolverá un problema de optimización para encontrar los parámetros $\theta$ que minimizan la función de coste $\mathcal{L}(\boldsymbol{\theta}; \mathcal{T})$.
    \end{exmp}
\end{mdframed}

Esta dificultad para aproximar soluciones de EDPs elípticas con PINN se debe a que las redes neuronales no son capaces de aproximar correctamente las condiciones de frontera. Para solucionar este problema, se han propuesto diferentes técnicas, como la inclusión de términos de regularización en la función de coste o la utilización de redes neuronales con arquitecturas específicas. No ob

\section{El ``Deep Ritz Method''}

\chapter{Resultados}\label{chap3}

\chapter{Partes eliminadas - NO IMPRIMIR}
\section{Espacios de funciones}

Para poder entender y formular de forma matemática el problema de aproximación de EDPs mediante redes neuronales, es necesario tener un conocimiento previo de los espacios de funciones en los que trabajamos. Como veremos más adelante al estudiar los problemas de frontera para EDPs elípticas, es importante tener una caracterización del espacio $H_1^0$. Para entenderlo, empezaremos por los espacios de Hilbert Soobolev.

\begin{mdframed}
\begin{defin}
    Seam $\Omega$ un conjunto abierto de $\mathbb{R}^n$. Definimos el espacio de Sobolev $H^1(\Omega)$ como el conjunto de funciones en el siguiente conjunto
    \begin{equation}
        H^1(\Omega)=\{u\in L^2(\Omega): \frac{\partial u}{\partial x_i}\in L^2(\Omega), \, i=1,\dots,n\}.
    \end{equation}
    En este espacio, se define la norma de funciones de con la siguiente ecuación
    \begin{equation}
        \|u\|_{H^1(\Omega)}=\left(\|u\|^2_{L^2(\Omega)} + \sum_{i=1}^{n}\left\|\frac{\partial u}{\partial x_i}\right\|^2_{L^2(\Omega)}\right)^{1/2}.
    \end{equation}
\end{defin}
\end{mdframed}

Dada esta definición, se define el espacio $H_0^1(\Omega)$ como el cierre de las funciones de $C_0^\infty(\Omega)$ en la norma de $H^1(\Omega)$. Es decir, $H_0^1(\Omega)$ es el conjunto de funciones $u\in H^1(\Omega)$ que se obtienen como límite en $H^1(\Omega)$ de una serie de funciones $\{u_m\}_{m=1}^\infty$ todas ellas en $C_0^\infty(\Omega)$. Así, de forma más simple, se puede demostrar que $H_0^1(\Omega)$ se trata del siguiente conjunto.

\begin{equation}
    H_0^1(\Omega)=\{u\in H^1(\Omega): u=0 \text{ en } \partial\Omega\}.
\end{equation}

Nótese que $H_0^1(\Omega)$ es un espacio de Hilbert con la misma norma y producto interno que $H^1(\Omega)$.



\begin{exmp}
    Es fácil ver por ejemplo que la función $u = x^2 + y^2 - 4$ pertenece a $H^1_0(C)$, siendo $C = \{(x,y)\in \mathbb{R}^2: x^2 + y^2 < 4\}$ el círculo abierto de radio 2 centrada en el origen. Esto se debe a que $u\in L^2(C)$ y además:
    \begin{equation*}
        \frac{\partial u}{\partial x} = 2x\in L^2(C), \quad \frac{\partial u}{\partial y} = 2y \in L^2(C), \quad u=0\text{ en  } \partial C.
    \end{equation*}
    Por tanto, $u\in H_0^1(C)$.
\end{exmp}


\section{Introducción a las ecuaciones en derivadas parciales}

Las ecuaciones en derivadas parciales (EDPs) son ecuaciones que relacionan una función desconocida con sus derivadas parciales. Son fundamentales en la física y en la ingeniería, ya que permiten modelar fenómenos físicos y predecir su evolución en el tiempo. 

Existen varios tipos de EDPs, no obstante, nosotros nos centraremos en los problemas de frontera para ecuaciones en derivadas parciales elípticas. Estas se utilizan para resolver problemas de equilibrio, que implican encontrar la solución de una ecuación diferencial en un dominio acotado con condiciones de frontera específicas. Estos problemas incluyen la distribución estacionaria de temperatura, el flujo de fluidos incompresibles no viscosos, la distribución de tensiones en sólidos en equilibrio, y el cálculo de campos eléctricos en regiones con densidad de carga. En general, se aplican cuando se busca determinar un potencial en situaciones estacionarias. 

Lo he sacado de: \href{https://www.ugr.es/~prodelas/ftp/ETSICCP/Resoluci%F3nNum%E9ricaEDPs.pdf}{este enlace, \colorbox{yellow}{este tipo de cosas se citan?}}


%se puede hablar de los espacios de funciones en los que trabajamos, que es el supp de una función. Poner un ejemplo de ecuación diferencial y por que no se puede encontrar su solución en forma fuerte
Uno de los primero ejemplos de este tipo de ecuaciones es la ecuación de Poisson,
\begin{equation*}
    -\Delta  u = f,
\end{equation*}
donde $\Delta$ es el operador laplaciano, que se define como la suma de las segundas derivadas parciales de la función $u$:
\begin{equation*}
    \Delta u = \sum_{i=1}^{n}\frac{\partial^2 u}{\partial x_i^2}
\end{equation*}

Esta ecuación es una EDP elíptica pues cumple la siguiente definición general.


\begin{mdframed}
\begin{defin}
    Dado un conjunto $\Omega$, acotado y abierto en $\mathbb{R}^n$, decimos que una ecuación en derivadas parciales es elíptica si:
    \begin{equation}
        -\sum_{i,j=1}^{n} \frac{\partial}{\partial x_j}\left( a_{ij}(x)\frac{\partial u}{\partial x_i}\right) + \sum_{i=1}^{n} b_i(x)\frac{\partial u}{\partial x_i} + c(x)u = f(x), \qquad x\in\Omega.
    \end{equation}
    Donde los coeficientes $a_{ij}(x)$, $b_i(x)$, $c(x)$ y $f$ son funciones que satisfacen las siguientes condiciones
    \begin{align}
        a_{ij} \in C^1(\overline{\Omega}),& \qquad i,j = 1, \dots ,n \\
        b_i, c \in C(\overline{\Omega}),& \qquad i = 1, \dots ,n \\
        c \in C(\overline{\Omega}),& \\
        f\in C(\overline{\Omega})&
    \end{align}
\end{defin}
\end{mdframed}

De entre los problemas elípticos definidos en \ref{def:EDP_eliptica}, como comentábamos, nos interesan las ecuaciones en derivadas parciales elípticas con condiciones de frontera, en concreto, las condiciones de frontera de Dirichlet.

\begin{mdframed}
\begin{defin}    
    El problema de condición de frontera de Dirichlet es concretamente el que tenemos una EDP elíptica como la definida en \ref{def:EDP_eliptica}, tal que, nuestra solución $u$, además de cumplir las ecuación \eqref{eq:EDP_eliptica}, cumple la siguiente condición de frontera
    \begin{equation}
        u(x) = g(x), \qquad \forall x\in\partial\Omega.
    \end{equation}
    Asimismo, el problema homogéneo de Dirichlet es aquel en el que $g=0$. A lo largo del trabajo nos centraremos principalmente en es te tipo de EDPs.
\end{defin}
\end{mdframed}

Con todo, el tipo de ecuaciones elípticas en el que nos vamos a centrar (entendiendo que se cumplen las condiciones de \eqref{eq:condiciones_EDP_eliptica_a} - \eqref{eq:condiciones_EDP_eliptica_f}) serán de la siguiente forma.
\begin{equation}
    \begin{cases}
        -\sum_{i,j=1}^{n} \frac{\partial}{\partial x_j}\left( a_{ij}(x)\frac{\partial u}{\partial x_i}\right) + \sum_{i=1}^{n} b_i(x)\frac{\partial u}{\partial x_i} + c(x)u = f(x), \qquad & x\in\Omega \\
        u(x) = 0, & x\in\partial\Omega.
    \end{cases}
\end{equation}

\section{Forma fuerte y débil de una EDP}
En la formulación que hemos dado de las ecuaciones en derivadas parciales elípticas, nos estábamos refiriendo a su formulación en forma fuerte. De forma intuitiva, esta es la que se obtiene directamente de la definición de la ecuación, y es la que relaciona la función desconocida con sus derivadas parciales. La solución de estas ecuaciones en forma fuerte es la que se conoce como solución clásica. De esto surge la siguiente definición.

\begin{mdframed}
\begin{defin}
    Una función $u \in C^2(\Omega)$ que cumples las condiciones de frontera de Dirichlet y satisface la ecuación \eqref{eq:EDP_eliptica} en $\Omega$ se dice que es una solución clásica o fuerte de la ecuación \eqref{eq:EDP_eliptica}. 
\end{defin}
\end{mdframed}

No obstante, en muchos casos, no es posible encontrar una solución en forma fuerte, es decir, una función que cumpla la ecuación en todo el dominio y que además cumpla las condiciones de frontera. En estos casos, se recurre a métodos alternativos, como la formulación débil de la ecuación, que permite encontrar una solución en un espacio de funciones más amplio. A continuación, vemos un ejemplo que motiva la necesidad de recurrir a la formulación débil de una ecuación.

\begin{exmp}
    Supongamos que tenemos la siguiente ecuación de Poisson con una condición de frontera de Dirichlet homogénea,
    \begin{equation*}
        \begin{cases}
            -\Delta u = f, & \text{en } \Omega,
            \\
            u = 0, & \text{en } \partial\Omega.
        \end{cases}
    \end{equation*}
    Donde $\Omega$ es un conjunto acotado y abierto en $\mathbb{R}^n$. En este caso, no siempre es posible encontrar una solución en forma fuerte, es decir, una función $u$ que cumpla la ecuación en todo el dominio $\Omega$ y que además cumpla la condición de frontera. Por ejemplo, si $f$ no es una función suave, no se puede garantizar la existencia de una solución en forma fuerte pues estaríamos rompiendo la condición de \eqref{eq:condiciones_EDP_eliptica_f}. En estos casos, se recurre a métodos alternativos, como la formulación débil de la ecuación, que permite encontrar una solución en un espacio de funciones más amplio. 
\end{exmp}


Para pasar de forma fuerte a débil, lo que hacemos es seguir el siguiente proceso
\begin{enumerate}
    \item Multiplicamos a ambos lados de la igualdad por una función $\varphi \in C^\infty_0(\Omega)$ e integramos.
    \begin{align*}
        \int_\Omega\left(-\sum_{i,j=1}^{n} \frac{\partial}{\partial x_j}\left( a_{ij}(x)\frac{\partial u}{\partial x_i}\right) + \sum_{i=1}^{n} b_i(x)\frac{\partial u}{\partial x_i} + c(x)u \right) \varphi  \,dx\\ =\int_\Omega f(x)\varphi  \,dx
    \end{align*}
    \item Expandimos la multiplicación e integramos por partes en la primera integral, llegando a
    \begin{align*}
        \sum_{i,j=1}^{n} \int_\Omega a_{ij}(x) \frac{\partial \varphi }{\partial x_j} \frac{\partial u}{\partial x_i} + \sum_{i=1}^{n} \int_\Omega b_i(x)\frac{\partial u}{\partial x_i}\varphi  + \int_\Omega c(x)\varphi u  \,dx\\ =\int_\Omega f(x)\varphi  \,dx
    \end{align*}
    Con esta manipulación hemos conseguido una cosa muy interesante: ya no tenemos segundas derivadas de $u$, es decir, ya no necesitamos que $u\in C^2$. Para que esta igualdad tenga sentido, solo hace falta que $u\in L^2(\Omega)$ y que $\partial y /\partial x_i \in L^2(\Omega),\, i =1,\dots,n$. Nótese además que, para que se cumpla la condición de frontera de Dirichlet, $u=0 \in \partial\Omega$. Todo esto se traduce a que $u\in H_0^1(\Omega)$ Esto simplifica las condiciones del problema pues el espacio de funciones en el que puede estar $u$, ahora es mucho más amplio.
    \item Para simplificar aun más el problema, nótese que $a_{ij}$ ya no aparecen tras derivadas de ningun tipo, luego no es necesario asumir que $a_{ij}\in C^1(\overline{\Omega})$, basta con que $a_{ij}\in L^\infty(\Omega)$. Por lo mismo, $b_i,\,c\in L^\infty(\Omega), i=1,\dots,n$ es suficiente.
    \item Por último, nótese que $C^\infty_0(\Omega) \subset H^1_0(\Omega)$, luego se puede ver que teniendo $u,v\in H^1_0(\Omega)$, nuestra ecuación sigue teniendo sentido. Con todo esto, surge la siguiente definición de forma débil.
\end{enumerate}

\printbibliography
\cleardoublepage


\end{document}
